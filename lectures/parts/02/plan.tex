\begin{frame}{Plan for Part \thislecture}

\begin{itemize}
{\small
\item Single-layer networks: The perceptron.
\item Loss functions.
\item Heuristic optimization of the original Mark I perceptron.
\item Stochastic gradient-descent method.
\item Percepton criterion.
\item Activation functions and their properties.
\item Variants of the perceptron and connection with other regression and classification models.
    \begin{itemize}
    {\small
        \item Least-squares regression and classification. Widrow-Hoff learning rule.
        \item Closed form solutions of least-squares regression.
        \item Logistic regregression.
        \item Support vector machines.
    }
    \end{itemize}
\item The multiclass perceptron.
\item Multiclass (Weston-Watkins) support vector machines.
\item Multinomial logistic regression (Softmax classifier).
}
\end{itemize}

\end{frame}
