
\begin{frame}[t]{Introduction}

Part \thispart focusses on {\bf shallow neural architectures}.\\
\vspace{0.2cm}

Simple neural network architectures containing only one or two layers 
can capture a host of \gls{ml} models.\\
\vspace{0.2cm}

We will highlight connections\footnote{
    Additional connections are explored in \cite{Aggarwal:2018SpringerDL}.
} with conventional
\gls{ml} models such as:
\begin{itemize}
    \item linear regression,
    \item support vector machines, and
    \item logistic regression.
\end{itemize}
\vspace{0.2cm}

Understanding how traditional methods can emerge from certain {\bf minor 
variations of a comprehensive neural architecture} is highly instructive.\\
\vspace{0.2cm}

These shallow networks are the {\bf building blocks of deeper architectures}
that we will study later in this module.\\

\end{frame}