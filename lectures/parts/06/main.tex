\renewcommand{\prevpart}{5 }
\renewcommand{\thispart}{6 }
\renewcommand{\nextpart}{7 }

\section{Convolutional Neural Networks}

% Cover page
\input{common/cover_part.tex}

% Outline
\input{common/toc_part.tex}

%
%
%

\begin{frame}[t,allowframebreaks]{Convolutional Neural Networks}

    A \index{CNN}\index{convolutional neural network}\gls{cnn} 
    is a specialised type of deep neural network designed for use 
    with {\bf grid-structured inputs}.\\
    Examples include:
    \begin{itemize}
      \item {\bf time series} (1-D grid-structured data), or 
      \item {\bf images} (2-D grid-structured data).
    \end{itemize}

    The vast majority of \gls{cnn} applications focusses on image data.
    In this type of data exhibits:
    \begin{itemize}
        \item Some degree of {\bf similarity in adjacent grid locations}.\\
          {\it For example, neighbouring pixels often have a similar colour.}
        \item A degree of {\bf translation invariance}.\\
          {\it For example, our interpretation of an object as a "cat"
          does not depend on where it appears on the image.}
    \end{itemize}

    \framebreak

    \glspl{cnn} use \index{convolution} \gls{convolution}
    operations in at least one of their layers.
    Convolution:
    \begin{itemize}
     \item is used in place of general matrix multiplication,
     \item enables parameter sharing 
    \end{itemize}

\end{frame}

% Discuss studies of the primary visual cortex (V1) by Hubel, Wiesel and others,
% and describe the workings of V1
\subsection{Biological inspirations}
\input{parts/06/biological_inspirations.tex}

% Discuss the Neocognitron
\subsection{Convolutional Network precursors: Neocognitron}
\input{parts/06/neocognitron.tex}

% Give a list of modern architectures, but defer detailed description 
% till after the basics of convolutional networks are described
\subsection{From the Neocognitron to modern convolutional architectures}
\input{parts/06/from_neocognitron_to_modern_architectures.tex}

% Discuss the mathematical operations of convolution and cross-correlation
\subsection{The convolution and cross-correlation operations}
\input{parts/06/convolution.tex}

% Discuss the main motivations for the use of convolutional architectures:
% sparse connectivity, parameter sharing, equivariant representations
\subsection{Motivation}
\input{parts/06/motivations_for_convolutional_architectures.tex}
\subsubsection{Sparse connectivity}
\input{parts/06/sparse_connectivity.tex}
\subsubsection{Parameter sharing}
\input{parts/06/parameter_sharing.tex}
\subsubsection{Equivariant representations}
\input{parts/06/equivariant_representations.tex}

%
%
%

\begin{frame}[t,allowframebreaks]{Basic structure of a Convolutional Neural Network -}

    The \index{CNN}\index{convolutional neural network}\gls{cnn} 
    input data (typically, an image) is a {\bf 3-D grid structure}
    that has {\it height}, {\it width} and {\it depth}:
    \begin{itemize}
        \item Two dimensions are devoted to {\bf spatial information}
        \item The third dimension stores {\bf independent properties} of each pixel
        \begin{itemize}
            \item For example, the {\bf intensities of the three primary colours}
             (red, green, and blue) that help us encode the precise colour of the pixel.
        \end{itemize}
    \end{itemize}

    \begin{columns}
        \begin{column}{0.22\textwidth}
            \vspace{0.0cm}
            \begin{center}
                \includegraphics[width=1.0\textwidth]
                    {./images/cnn/example_inputs/example_1_cat.png}\\
            \end{center}
        \end{column}
        \begin{column}{0.46\textwidth}
            \vspace{0.0cm}
            \begin{center}
                \includegraphics[width=1.0\textwidth]
                  {./images/cnn/example_inputs/example_1_cat_rgb.png}\\
            \end{center}      
        \end{column}
        \begin{column}{0.32\textwidth}
            \vspace{0.0cm}
            \begin{center}
                \includegraphics[width=1.0\textwidth]
                  {./images/cnn/example_inputs/example_1_cat_array.png}\\
            \end{center}      
        \end{column}
    \end{columns}
    \begin{center}
        {\scriptsize 
        \color{col:attribution} 
        Image adapted from \cite{DevCommunity:GoingFurtherWithCNN}}\\
    \end{center}      

    \framebreak

    A \index{CNN}\index{convolutional neural network}\gls{cnn} consists of {\bf several layers}

    \begin{itemize}
        \item
            Like in traditional \index{feed forward}\glshyph{feed forward} neural networks, 
            and each layer processes information produced at the layer that precedes it.
        \item
            Typically, {\bf three types of layers}:
            \index{convolution}\gls{convolution}, 
            \index{pooling}\gls{pooling} and 
            \index{ReLU}\gls{relu}.
        \item
            Connections are sparse, though the latter part can be fully connected.
        \item
            {\bf Spatial relationships are preserved} between layers
    \end{itemize}

    \begin{center}
        \includegraphics[width=0.8\textwidth]
          {./images/cnn/basic_structure/chatterjee19_classic_cnn_architecture.png}\\
        {\scriptsize 
          Classic CNN architecture.
          \color{col:attribution} 
          Image from \cite{TowardsDataScience:BasicsOfClassicCNN}}\\    
    \end{center}      

    \framebreak

    In a \index{CNN}\index{convolutional neural network}\gls{cnn},
    parameters are organised in a number of 
    \index{filter}\glspl{filter} (or \index{kernel}\glspl{kernel}).
    \begin{itemize}
        \item
        The number of \glspl{filter} controls the {\bf capacity of the model}.
        \item 
        The \glspl{filter} are learnt during training.
        \item 
        A \gls{filter} is a {\bf feature detector}.
    \end{itemize}

    \vspace{0.2cm}

    A \gls{filter} applied to a layer generates 
    a \index{feature map}\gls{feature map} of the next layer.
    \begin{itemize}
        \item
        The \glspl{filter} have the {\bf same grid structure} as the layer they are applied to,
        but they are {\bf much smaller in size} (and usually square).
        \item
        The number of filters in a layer determines the depth of the next layer.
    \end{itemize}

    \begin{blockexample}{}
        \small
        The {\bf depth of a layer} should \underline{not be confused} 
        with the {\bf depth of the network}.
        \begin{itemize}
          \item The depth of a layer is the number of feature maps in that layer.
          \item The depth of the network is the number of layers in the network.
        \end{itemize}
    \end{blockexample}

    \framebreak

    A {\bf single feature} is generated by 
    \begin{itemize}
      \item 
      Overlaying a \gls{filter} at a specific position on a layer, and
      \item 
      calculating the sum over the elements of an element-wise product 
      (i.e. the {\em dot product}) between:
      \begin{itemize}
        \item the filter, and
        \item the subset of the layer spanned by the filter
      \end{itemize}
    \end{itemize}

    \begin{columns}
        \begin{column}{0.60\textwidth}
            \begin{center}
                \includegraphics[width=0.97\textwidth]
                  {./images/cnn/convolution/bansal19_convolution_illustration.png}\\
                {\scriptsize 
                  \color{col:attribution} 
                  Image from \cite{Kaggle:3DConvolutions}}\\    
            \end{center}      
        \end{column}
        \begin{column}{0.40\textwidth}
            \vspace{0.0cm}
        \end{column}
    \end{columns}

    \framebreak

    \begin{columns}
        \begin{column}{0.60\textwidth}
            \begin{center}
                \includegraphics[width=1.00\textwidth]
                  {./images/cnn/convolution/aggarwal_convolution_illustration_1.png}\\
                {\scriptsize 
                  \color{col:attribution} 
                  Image reproduced from \cite{Aggarwal:2018SpringerDL} (Fig 8.2)}\\    
            \end{center}      
        \end{column}
        \begin{column}{0.40\textwidth}
            \vspace{0.0cm}
        \end{column}
    \end{columns}

    \framebreak

    \begin{center}
        \includegraphics[width=1.00\textwidth]
          {./images/cnn/convolution/aggarwal_convolution_illustration_2.png}\\
        {\scriptsize 
          \color{col:attribution} 
          Image reproduced from \cite{Aggarwal:2018SpringerDL} (Fig 8.1)}\\    
    \end{center}      

\end{frame}


\subsection{Case studies}


\subsubsection{LeNet-5}

\subsubsection{AlexNet}

\subsubsection{GoogLeNet}

\subsubsection{ResNet}

% Main points to remember
%\renewcommand{\partsummarytitle}{Main points to remember }
%\input{parts/06/summary.tex}

% Preview of next part
%\input{parts/06/next.tex}

% Suggested reading for this part
\subsection{Suggested reading}
\input{parts/06/reading.tex}
