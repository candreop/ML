# Machine Learning 

This repository includes handouts and codes I used for delivering the Machine Learning module at the Department of Physics of the University of Liverpool.

## Author

Prof. Costas Andreopoulos, **FHEA**  < constantinos.andreopoulos \at cern.ch >

<pre>
 University of Liverpool          |  U.K. Research & Innovation (UKRI)
 Faculty of Science & Engineering |  Science & Technology Facilities Council (STFC)
 School of Physical Sciences      |  Rutherford Appleton Laboratory 
 Department of Physics            |  Particle Physics Department
 Oliver Lodge Lab 316             |  Harwell Oxford Campus, R1 2.89
 Liverpool L69 7ZE, UK            |  Oxfordshire OX11 0QX, UK          
 tel: +44-(0)1517-943201          |  tel: +44-(0)1235-445091 
</pre>


## Aims of the module
- To introduce the fundamental concepts of machine learning.
- To develop the ability of students to address common real-world problems using one of the leading open source frameworks for machine learning.

## Syllabus
- Training neural networks, backpropagation
- Supervised and unsupervised learning algorithms
- Stochastic Gradient Descent (SGD)
- Batch normalization
- Convolutional Neural Networks (CNN)
- Classification and semantic segmentation using CNNs
- Generative Adversarial Networks (GANs)
- Case studies from science and industry

## Structure

### ML Prep Session (2 hrs)

- Linear algebra reminders
- Probability theory reminders

### ML Lecture 1 (1 hr)

- Introduction
- Human vs computer learning
- Biologically inspired methods of computer learning
- Basic architecture of neural networks

### ML Lecture 2 (1 hr)

- Single-layer networks: The Perceptron
- Loss functions
- Heuristic optimization of the original Mark I perceptron
- Stochastic gradient-descent method
- Percepton criterion
- Activation functions and their properties
- Connections with least-squares regression, logistic regregression and support vector machines

### ML Lecture 3 (1 hr)

- Multi-layer networks
- Training neural networks with backpropagation 
- Practical issues in neural network training

### ML Lecture 4 (1 hr)

### ML Lecture 5 (1 hr)

### ML Lecture 6 (1 hr)

### ML Lecture 7 (1 hr)

### ML Lecture 8 (1 hr)

### ML Lecture 9 (1 hr)

### ML Lecture 10 (1 hr)

### ML Lecture 11 (1 hr)

### ML Lecture 12 (1 hr)

### ML Lecture 13 (1 hr)

### ML Lecture 14 (1 hr)

### ML Lecture 15 (1 hr)


### ML Workshop Prep Session (2 hrs)

- Introduction to pyTorch


### ML Workshop 1 (2 hrs)


### ML Workshop 2 (2 hrs)


### ML Workshop 3 (2 hrs)


### ML Workshop 4 (2 hrs)


### ML Workshop 5 (2 hrs)


### ML Project (10 hrs)


## Reading list

### Key textbooks

- Ian Goodfellow, Yoshua Bengio and Aaron Courville, Deep Learning, MIT Press (2016)
- Charu Aggarwal, Neutral Networks and Deep Learning - A Textbook, Springer (2018)
 
### Other useful reading

- Aurélien Géron, Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow - Concepts, Tools, and Techniques to Build Intelligent System, O'Reilly, 2019

### Documentation for codes used in the module

- PyTorch documentation, https://pytorch.org/docs/stable/
- PyTorch tutorials, https://pytorch.org/tutorials/

### Relevant research articles

- ImageNet Classification with Deep Convolutional Neural Networks, https://doi.org/10.1145/3065386
- GoogleNet, arXiv:1409.4842
- R-CNN, arXiv:1311.2524
- Fast R-CNN, arXiv:1504.08083
- Faster R-CNN, arXiv:1506.01497
- Fully Convolutional Neural Nets for Semantic Segmentation, arXiv:1605.06211
- Mask R-CNN, arXiv:1703.06870
- Multiview CNN, arXiv:1505.00880
- Generative Adversarial Nets, arXiv:1406.2661
- Deep Convolutional Generative Adversarial Nets, arXiv:1511.06434
